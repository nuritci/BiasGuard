{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Choose dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wxVZmbDk7m2L"
      },
      "outputs": [],
      "source": [
        "# DATASET_NAME = 'COMPAS_SEX'\n",
        "# PROT_ATTR_IDX = 5 #COMPAS_SEX\n",
        "\n",
        "DATASET_NAME = 'RECRUIT_SEX'\n",
        "PROT_ATTR_IDX = 0 #RECRUIT_SEX \n",
        "\n",
        "# DATASET_NAME = 'ADULT_RACE'\n",
        "# PROT_ATTR_IDX = 8 #ADULT_RACE \n",
        "\n",
        "# DATASET_NAME = 'SURGICAL_AGE'\n",
        "# PROT_ATTR_IDX = 1 #SURGICAL_AGE\n",
        "\n",
        "# DATASET_NAME = 'LAW_SEX'\n",
        "# PROT_ATTR_IDX = 8 #LAW_SEX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUrcK60mx6-_",
        "outputId": "4ef4d9f2-98a1-4251-d81a-fb5d5c664d94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn-intelex in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (2024.5.0)\n",
            "Requirement already satisfied: daal4py==2024.5.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from scikit-learn-intelex) (2024.5.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from scikit-learn-intelex) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.19 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from daal4py==2024.5.0->scikit-learn-intelex) (1.24.4)\n",
            "Requirement already satisfied: daal==2024.5.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from daal4py==2024.5.0->scikit-learn-intelex) (2024.5.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from daal==2024.5.0->daal4py==2024.5.0->scikit-learn-intelex) (2021.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.4.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from scikit-learn>=0.22->scikit-learn-intelex) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn-intelex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v7h2dDOE7m2Q"
      },
      "outputs": [],
      "source": [
        "CTGAN_FACTOR = 5\n",
        "N_AUG = 6\n",
        "NFOLDS = 5\n",
        "EXP = 'RF'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        }
      ],
      "source": [
        "# Update numpy to a compatible version\n",
        "import scipy as sp\n",
        "from scipy.io import arff\n",
        "import numpy as np\n",
        "from sklearnex import patch_sklearn\n",
        "patch_sklearn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tcxri1m4CPr",
        "outputId": "33bbffb9-e8fc-4eeb-89b5-3ebffb9a0e80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ctgan in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (0.10.2)\n",
            "Requirement already satisfied: rdt>=1.11.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from ctgan) (1.13.2)\n",
            "Requirement already satisfied: tqdm<5,>=4.29 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from ctgan) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from ctgan) (1.24.4)\n",
            "Requirement already satisfied: torch>=1.9.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from ctgan) (1.10.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from ctgan) (2.0.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from pandas>=1.4.0->ctgan) (2022.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from pandas>=1.4.0->ctgan) (2024.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from pandas>=1.4.0->ctgan) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->ctgan) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.7.3 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from rdt>=1.11.0->ctgan) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from rdt>=1.11.0->ctgan) (1.2.2)\n",
            "Requirement already satisfied: Faker>=17 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from rdt>=1.11.0->ctgan) (33.3.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from Faker>=17->rdt>=1.11.0->ctgan) (4.12.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from scikit-learn>=1.0.2->rdt>=1.11.0->ctgan) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from scikit-learn>=1.0.2->rdt>=1.11.0->ctgan) (1.4.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from tqdm<5,>=4.29->ctgan) (0.4.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install ctgan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1no9nwXY4JPx",
        "outputId": "00c12669-48ea-421c-9411-76b35b0c07ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sdv in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (1.17.3)\n",
            "Requirement already satisfied: deepecho>=0.6.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from sdv) (0.6.1)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.28 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from sdv) (1.35.93)\n",
            "Requirement already satisfied: platformdirs>=4.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from sdv) (4.3.6)\n",
            "Requirement already satisfied: graphviz>=0.13.2 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from sdv) (0.20.3)\n",
            "Requirement already satisfied: botocore<2.0.0,>=1.31 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from sdv) (1.35.93)\n",
            "Requirement already satisfied: copulas>=0.12.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from sdv) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from sdv) (1.24.4)\n",
            "Requirement already satisfied: ctgan>=0.10.2 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from sdv) (0.10.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from sdv) (6.0.2)\n",
            "Requirement already satisfied: cloudpickle>=2.1.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from sdv) (3.1.0)\n",
            "Requirement already satisfied: sdmetrics>=0.17.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from sdv) (0.18.0)\n",
            "Requirement already satisfied: rdt>=1.13.2.dev0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from sdv) (1.13.2)\n",
            "Requirement already satisfied: tqdm>=4.29 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from sdv) (4.64.0)\n",
            "Requirement already satisfied: pandas>=1.4.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from sdv) (2.0.3)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from boto3<2.0.0,>=1.28->sdv) (0.10.4)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from boto3<2.0.0,>=1.28->sdv) (1.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from botocore<2.0.0,>=1.31->sdv) (1.26.20)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from botocore<2.0.0,>=1.31->sdv) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.7.3 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from copulas>=0.12.0->sdv) (1.10.1)\n",
            "Requirement already satisfied: plotly>=5.10.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from copulas>=0.12.0->sdv) (5.24.1)\n",
            "Requirement already satisfied: torch>=1.9.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from ctgan>=0.10.2->sdv) (1.10.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from pandas>=1.4.0->sdv) (2024.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from pandas>=1.4.0->sdv) (2022.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from plotly>=5.10.0->copulas>=0.12.0->sdv) (8.0.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from plotly>=5.10.0->copulas>=0.12.0->sdv) (21.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.31->sdv) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from rdt>=1.13.2.dev0->sdv) (1.2.2)\n",
            "Requirement already satisfied: Faker>=17 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from rdt>=1.13.2.dev0->sdv) (33.3.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from Faker>=17->rdt>=1.13.2.dev0->sdv) (4.12.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from scikit-learn>=1.0.2->rdt>=1.13.2.dev0->sdv) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from scikit-learn>=1.0.2->rdt>=1.13.2.dev0->sdv) (3.1.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from tqdm>=4.29->sdv) (0.4.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from packaging->plotly>=5.10.0->copulas>=0.12.0->sdv) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install sdv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s1uszooW4fNR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from sdv.metadata import SingleTableMetadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NFIkZNpN4oFZ"
      },
      "outputs": [],
      "source": [
        "from sdv.single_table import CTGANSynthesizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stb197QFMuax",
        "outputId": "347f6778-1460-4819-c921-0b48d119e1f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (0.19.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from wandb) (2.19.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: eval-type-backport in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from wandb) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from wandb) (2.10.4)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from wandb) (5.8.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from wandb) (5.29.2)\n",
            "Requirement already satisfied: setproctitle in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from wandb) (8.0.4)\n",
            "Requirement already satisfied: setuptools in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from wandb) (61.2.0)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: platformdirs in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: colorama in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.4)\n",
            "Requirement already satisfied: six>=1.4.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V4rOQr5LM8wF"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-4sd0lzNEdy",
        "outputId": "b8a6049f-c023-4469-c3f8-2df64e7da273"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrabaevn\u001b[0m (\u001b[33mrabaevn-ben-gurion-university-of-the-negev\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\seffi\\_netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login(key='a6bbbea4dc56f4a415d7e588526ee9bab53ccdfb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPp56Mpw7m2S",
        "outputId": "8e97c165-ead4-47aa-f561-a56cf46c9362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fairlearn in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (0.12.0)\n",
            "Requirement already satisfied: pandas>=2.0.3 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from fairlearn) (2.0.3)\n",
            "Requirement already satisfied: scipy>=1.9.3 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from fairlearn) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from fairlearn) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from fairlearn) (1.24.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from pandas>=2.0.3->fairlearn) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from pandas>=2.0.3->fairlearn) (2024.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from pandas>=2.0.3->fairlearn) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from scikit-learn>=1.2.1->fairlearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install fairlearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GThrm7GR7m2T",
        "outputId": "87ccb8e6-95ce-4485-d87b-5cb20cc33f6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn==1.2.2 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (1.2.2)\n",
            "Requirement already satisfied: category_encoders in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (2.6.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from scikit-learn==1.2.2) (1.24.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from scikit-learn==1.2.2) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from scikit-learn==1.2.2) (3.1.0)\n",
            "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from category_encoders) (2.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from category_encoders) (0.5.2)\n",
            "Requirement already satisfied: importlib-resources in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from category_encoders) (5.2.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from category_encoders) (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2022.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2024.2)\n",
            "Requirement already satisfied: six in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: packaging>=21.3 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.4)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages (from importlib-resources->category_encoders) (3.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn==1.2.2 category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "X5qVScCe7m2T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "\n",
        "import os\n",
        "import math\n",
        "import gc\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, auc, roc_auc_score, confusion_matrix\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "from fairlearn.postprocessing import ThresholdOptimizer\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import graphviz\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "from datetime import date\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p_mC9MO7m2U",
        "outputId": "a881798d-ae2e-43f0-f71f-bfaad6ded58d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sdv\\single_table\\base.py:104: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
            "  warnings.warn(\n",
            "Gen. (1.12) | Discrim. (-0.02): 100%|██████████| 100/100 [00:48<00:00,  2.07it/s]\n"
          ]
        }
      ],
      "source": [
        "if DATASET_NAME == 'ADULT_SEX':\n",
        "    TARGET_COL = 'income'\n",
        "    PRIV_FEATURE = \"sex\"\n",
        "    PRIV_VALUE_FEATURE = 1 # in this dataset the target = 0 is unfavorable.\n",
        "    PRIV_GROUP = 1 # male\n",
        "    data = pd.read_csv('Data/adult.csv')\n",
        "    data[TARGET_COL] = data[TARGET_COL].apply(lambda x: 0 if x == '<=50K' else 1)\n",
        "    data['sex'] = np.where(data['sex'] == 'Male', 0,1)\n",
        "    data['white'] = np.where(data['race'] == 'White', 1,0)\n",
        "\n",
        "\n",
        "    feature_columns = ['age', 'workclass', 'fnlwgt', 'education', 'education.num',\n",
        "       'marital.status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital.gain', 'capital.loss', 'hours.per.week', 'native.country', 'white']\n",
        "\n",
        "    CATEGORICAL = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'native.country']\n",
        "    #CTGAN\n",
        "    metadata1 = SingleTableMetadata()\n",
        "    metadata1.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan1 = CTGANSynthesizer(metadata1, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan1.fit(data[feature_columns])\n",
        "    ctgan1.save('ctgan_adult_sex.pkl')\n",
        "\n",
        "\n",
        "elif DATASET_NAME == 'CREDIT_SEX':\n",
        "    data = pd.read_csv('Data/german_credit_data.csv')\n",
        "    TARGET_COL = 'Risk'\n",
        "    PRIV_FEATURE = 'Sex'\n",
        "    PRIV_GROUP = 1\n",
        "    # in this dataset the target = 1 is unfavorable.\n",
        "    PRIV_VALUE_FEATURE = 0\n",
        "    data[TARGET_COL] = data[TARGET_COL].apply(lambda x: 0 if x == 'bad' else 1)\n",
        "    data['Sex'] = np.where(data['Sex'] == 'male', 0,1)\n",
        "    data = data.drop([\"Unnamed: 0\"],axis=1)\n",
        "    data['young'] = data['Age'].apply(lambda x: 0 if x < 25 else 1)\n",
        "    CATEGORICAL = ['Housing', 'Saving accounts' , 'Checking account', 'Purpose']\n",
        "    feature_columns = ['Age', 'Sex', 'Job', 'Housing', 'Saving accounts', 'Checking account','Credit amount', 'Duration', 'Purpose']\n",
        "    #N_AUG = 2\n",
        "    #CTGAN\n",
        "    metadata2 = SingleTableMetadata()\n",
        "    metadata2.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan2 = CTGANSynthesizer(metadata2, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan2.fit(data[feature_columns])\n",
        "    ctgan2.save('ctgan_credit_sex.pkl')\n",
        "\n",
        "elif DATASET_NAME == 'RECRUIT_SEX':\n",
        "    data = pd.read_csv('Data/recruitmentdataset-2022-1.3.csv')\n",
        "    TARGET_COL = 'decision'\n",
        "    PRIV_FEATURE = 'gender'\n",
        "    PRIV_GROUP = 0\n",
        "    # in this dataset the target = 0 is unfavorable.\n",
        "    PRIV_VALUE_FEATURE = 1\n",
        "    data['gender'] = np.where(data['gender'] == 'male', 0,1)\n",
        "    data['decision'] = np.where(data['decision'] == False, 0,1)\n",
        "    CATEGORICAL = [ 'nationality', 'sport',\n",
        "       'ind-debateclub', 'ind-programming_exp', 'ind-international_exp',\n",
        "       'ind-entrepeneur_exp', 'ind-exact_study', 'ind-degree',\n",
        "       'company']\n",
        "    feature_columns = ['gender', 'age', 'nationality', 'sport', 'ind-university_grade',\n",
        "       'ind-debateclub', 'ind-programming_exp', 'ind-international_exp',\n",
        "       'ind-entrepeneur_exp', 'ind-languages', 'ind-exact_study', 'ind-degree',\n",
        "       'company']\n",
        "\n",
        "    #CTGAN\n",
        "    metadata3 = SingleTableMetadata()\n",
        "    metadata3.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan3 = CTGANSynthesizer(metadata3, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan3.fit(data[feature_columns])\n",
        "    ctgan3.save('ctgan_recruit_sex.pkl')\n",
        "\n",
        "elif DATASET_NAME =='COMPAS_SEX':\n",
        "    data = pd.read_csv('Data/compas-scores-two-years_v1.csv')\n",
        "    TARGET_COL = 'two_year_recid'\n",
        "    data['sex'] = np.where(data['sex'] == 'Male', 0,1)\n",
        "    PRIV_FEATURE = 'sex'\n",
        "    PRIV_GROUP = 1\n",
        "    # in this dataset the target = 1 is unfavorable.\n",
        "    PRIV_VALUE_FEATURE = 0\n",
        "    feature_columns = ['sex', 'age', 'age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree' , 'score_text', 'v_score_text']\n",
        "    CATEGORICAL = [ 'age_cat', 'race', 'c_charge_degree', 'score_text', 'v_score_text']\n",
        "    #CTGAN\n",
        "    metadata4 = SingleTableMetadata()\n",
        "    metadata4.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan4 = CTGANSynthesizer(metadata4, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan4.fit(data[feature_columns])\n",
        "    ctgan4.save('ctgan_compas_sex.pkl')\n",
        "\n",
        "elif DATASET_NAME == 'DIABETES_AGE':\n",
        "    data = pd.read_csv('Data/diabetes_prediction_dataset.csv')\n",
        "    TARGET_COL = 'diabetes'\n",
        "    data['age_binary'] = data['age'].apply(lambda x: 0 if x < 40 else 1)\n",
        "    PRIV_FEATURE = 'age_binary'\n",
        "    PRIV_GROUP = 1\n",
        "    # in this dataset the target = 1 is unfavorable.\n",
        "    PRIV_VALUE_FEATURE = 0\n",
        "    feature_columns = ['gender', 'age_binary', 'hypertension', 'heart_disease', 'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
        "    CATEGORICAL = ['smoking_history', 'gender']\n",
        "    #CTGAN\n",
        "    metadata5 = SingleTableMetadata()\n",
        "    metadata5.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan5 = CTGANSynthesizer(metadata5, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan5.fit(data[feature_columns])\n",
        "    ctgan5.save('ctgan_diabetes_age.pkl')\n",
        "\n",
        "elif DATASET_NAME == 'BANK_AGE':\n",
        "    data = pd.read_csv('Data/bank.csv')\n",
        "    data['age'] = np.where(data['age'] < 40, 0, 1)\n",
        "    data['deposit'] = np.where(data['deposit'] == \"no\", 0,1)\n",
        "    TARGET_COL = 'deposit'\n",
        "    PRIV_FEATURE = 'age'\n",
        "    PRIV_GROUP = 0\n",
        "    # in this dataset target = 0 is unfavorable\n",
        "    PRIV_VALUE_FEATURE = 1\n",
        "    feature_columns = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']\n",
        "    CATEGORICAL = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "    #CTGAN\n",
        "    metadata6 = SingleTableMetadata()\n",
        "    metadata6.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan6 = CTGANSynthesizer(metadata6, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan6.fit(data[feature_columns])\n",
        "    ctgan6.save('ctgan_bank_age.pkl')\n",
        "\n",
        "\n",
        "elif DATASET_NAME == 'DEFAULT_CREDIT_SEX':\n",
        "    data = pd.read_csv('Data/UCI_Credit_Card.csv')\n",
        "    data['SEX'] = np.where(data['SEX'] == 1, 0, 1) # male - 0, female - 1\n",
        "    TARGET_COL = 'default.payment.next.month'\n",
        "    PRIV_FEATURE = 'SEX'\n",
        "    PRIV_GROUP = 0\n",
        "    # in this dataset target = 1 is unfavorable\n",
        "    PRIV_VALUE_FEATURE = 0\n",
        "    feature_columns = [\"LIMIT_BAL\", \"SEX\", \"EDUCATION\", \"MARRIAGE\", \"AGE\",\n",
        "    \"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\",\n",
        "    \"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\",\n",
        "    \"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\"]\n",
        "    CATEGORICAL = []\n",
        "    #CTGAN\n",
        "    metadata7 = SingleTableMetadata()\n",
        "    metadata7.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan7 = CTGANSynthesizer(metadata7, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan7.fit(data[feature_columns])\n",
        "    ctgan7.save('ctgan_default_credit_sex.pkl')\n",
        "\n",
        "elif DATASET_NAME == 'NURSERY_OCC':\n",
        "    data = pd.read_csv('Data/nursery.csv')\n",
        "    data['parents'] = np.where(data['parents'] == 'great_pret', 0, 1)\n",
        "    data['final evaluation'] = np.where(data['final evaluation'] == 'not_recom', 0, 1)\n",
        "    data['children'] = np.where(data['children'] == \"more\", 4, data['children'])\n",
        "    TARGET_COL = 'final evaluation'\n",
        "    PRIV_FEATURE = 'parents'\n",
        "    PRIV_GROUP = 0\n",
        "    # in this dataset target = 0 is unfavorable\n",
        "    PRIV_VALUE_FEATURE = 1\n",
        "    feature_columns = [\"parents\", \"has_nurs\", \"form\", \"children\", \"housing\", \"finance\", \"social\", \"health\"] # we dont use health becuase it has high correlation with the target\n",
        "    CATEGORICAL = [\"has_nurs\", \"form\", \"housing\", \"finance\", \"social\", \"health\"]\n",
        "    #CTGAN\n",
        "    metadata8 = SingleTableMetadata()\n",
        "    metadata8.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan8 = CTGANSynthesizer(metadata8, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan8.fit(data[feature_columns])\n",
        "    ctgan8.save('ctgan_nursery_occ.pkl')\n",
        "\n",
        "elif DATASET_NAME == 'COMPAS_RACE':\n",
        "    data = pd.read_csv('Data/compas-scores-two-years_v1.csv')\n",
        "    TARGET_COL = 'two_year_recid'\n",
        "    data['race'] = np.where(data['race'] == 'African-American', 0,1)\n",
        "    PRIV_FEATURE = 'race'\n",
        "    PRIV_GROUP = 1\n",
        "    # in this dataset the target = 1 is unfavorable.\n",
        "    PRIV_VALUE_FEATURE = 0\n",
        "    feature_columns = ['sex', 'age', 'age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree' , 'score_text', 'v_score_text']\n",
        "    CATEGORICAL = ['sex', 'age_cat', 'c_charge_degree', 'score_text', 'v_score_text']\n",
        "    #CTGAN\n",
        "    metadata9 = SingleTableMetadata()\n",
        "    metadata9.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan9 = CTGANSynthesizer(metadata9, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan9.fit(data[feature_columns])\n",
        "    ctgan9.save('ctgan_compas_race.pkl')\n",
        "\n",
        "elif DATASET_NAME == 'ADULT_RACE':\n",
        "    TARGET_COL = 'income'\n",
        "    PRIV_FEATURE = 'race'\n",
        "    PRIV_VALUE_FEATURE = 1 # in this dataset the target = 0 is unfavorable.\n",
        "    PRIV_GROUP = 1 # white\n",
        "    data = pd.read_csv('Data/adult.csv')\n",
        "    data[TARGET_COL] = data[TARGET_COL].apply(lambda x: 0 if x == '<=50K' else 1)\n",
        "    data['race'] = np.where(data['race'] == 'Black', 0,1)\n",
        "    data['white'] = np.where(data['race'] == 'White', 1,0)\n",
        "    feature_columns = ['age', 'workclass', 'fnlwgt', 'education', 'education.num',\n",
        "       'marital.status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital.gain', 'capital.loss', 'hours.per.week', 'native.country', 'white']\n",
        "\n",
        "    CATEGORICAL = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'sex', 'native.country']\n",
        "    #CTGAN\n",
        "    metadata10 = SingleTableMetadata()\n",
        "    metadata10.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan10 = CTGANSynthesizer(metadata10, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan10.fit(data[feature_columns])\n",
        "    ctgan10.save('ctgan_adult_race.pkl')\n",
        "\n",
        "elif DATASET_NAME == 'MIMIC_SEX':\n",
        "    TARGET_COL = 'outcome'\n",
        "    PRIV_FEATURE = 'gendera'\n",
        "    PRIV_VALUE_FEATURE = 1 # in this tadaset target = 0 is unfavorable\n",
        "    PRIV_GROUP = 1 # male\n",
        "    data = pd.read_csv('Data/MIMIC2.csv')\n",
        "    data['gendera'] = np.where(data['gendera'] == 2, 0, 1)\n",
        "    feature_columns = ['group', 'age', 'gendera', 'BMI', 'hypertensive',\n",
        "       'atrialfibrillation', 'CHD with no MI', 'diabetes', 'deficiencyanemias',\n",
        "       'depression', 'Hyperlipemia', 'Re-999l failure', 'COPD', 'heart rate',\n",
        "       'Systolic blood pressure', 'Diastolic blood pressure',\n",
        "       'Respiratory rate', 'temperature', 'SP O2', 'Urine output',\n",
        "       'hematocrit', 'RBC', 'MCH', 'MCHC', 'MCV', 'RDW', 'Leucocyte',\n",
        "       'Platelets', 'Neutrophils', 'Basophils', 'Lymphocyte', 'PT', 'INR',\n",
        "       'NT-proBNP', 'Creatine ki-999se', 'Creatinine', 'Urea nitrogen',\n",
        "       'glucose', 'Blood potassium', 'Blood sodium', 'Blood calcium',\n",
        "       'Chloride', 'Anion gap', 'Magnesium ion', 'PH', 'Bicarbo-999te',\n",
        "       'Lactic acid', 'PCO2', 'EF']\n",
        "    # if not working remove gendera from categorical\n",
        "    CATEGORICAL =  [\n",
        "    'group', 'hypertensive', 'atrialfibrillation',\n",
        "    'CHD with no MI', 'diabetes', 'deficiencyanemias', 'depression',\n",
        "    'Hyperlipemia', 'Re-999l failure', 'COPD'\n",
        "    ]\n",
        "\n",
        "    #CTGAN\n",
        "    metadata11 = SingleTableMetadata()\n",
        "    metadata11.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan11 = CTGANSynthesizer(metadata11, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan11.fit(data[feature_columns])\n",
        "    ctgan11.save('ctgan_mimic_sex.pkl')\n",
        "\n",
        "elif DATASET_NAME == 'MATERNAL_AGE':\n",
        "    TARGET_COL = 'RiskLevel'\n",
        "    PRIV_FEATURE = 'Age'\n",
        "    PRIV_VALUE_FEATURE = 0 #in this dataset target = 1 is unfavorable\n",
        "    PRIV_GROUP = 0 #young\n",
        "    data = pd.read_csv('Data/MaternalBinary.csv')\n",
        "    data['Age'] = np.where(data['Age'] < 40, 0, 1)\n",
        "    feature_columns = ['Age', 'SystolicBP', 'DiastolicBP', 'BS', 'BodyTemp', 'HeartRate']\n",
        "    CATEGORICAL = []\n",
        "\n",
        "    #CTGAN\n",
        "    metadata12 = SingleTableMetadata()\n",
        "    metadata12.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan12 = CTGANSynthesizer(metadata12, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan12.fit(data[feature_columns])\n",
        "    ctgan12.save('ctgan_maternal_age.pkl')\n",
        "\n",
        "elif DATASET_NAME == 'MESO_SEX':\n",
        "    TARGET_COL = 'class of diagnosis'\n",
        "    PRIV_FEATURE = 'gender'\n",
        "    PRIV_VALUE_FEATURE = 0 # in this dataset, target = 1 is unfavorable\n",
        "    PRIV_GROUP = 1 #male\n",
        "    data = pd.read_csv('Data/Mesothelioma.csv')\n",
        "    feature_columns = ['age', 'gender', 'city', 'asbestos exposure', 'type of MM', 'duration of asbestos exposure',\n",
        "                       'keep side', 'cytology', 'duration of symptoms', 'dyspnoea', 'ache on chest', 'weakness',\n",
        "                       'habit of cigarette', 'performance status', 'white blood', 'cell count (WBC)', 'hemoglobin (HGB)',\n",
        "                       'platelet count (PLT)', 'sedimentation', 'blood lactic dehydrogenise (LDH)', 'alkaline phosphatise (ALP)',\n",
        "                       'total protein', 'albumin', 'glucose', 'pleural lactic dehydrogenise', 'pleural protein',\n",
        "                       'pleural albumin', 'pleural glucose', 'dead or not', 'pleural effusion', 'pleural thickness on tomography',\n",
        "                       'pleural level of acidity (pH)', 'C-reactive protein (CRP)']\n",
        "    CATEGORICAL = ['city', 'asbestos exposure', 'type of MM', 'keep side', 'cytology', 'dyspnoea', 'ache on chest',\n",
        "                   'weakness', 'habit of cigarette', 'performance status', 'hemoglobin (HGB)', 'dead or not', 'pleural effusion',\n",
        "                   'pleural thickness on tomography', 'pleural level of acidity (pH)']\n",
        "    #CTGAN\n",
        "    metadata13 = SingleTableMetadata()\n",
        "    metadata13.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan13 = CTGANSynthesizer(metadata13, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan13.fit(data[feature_columns])\n",
        "    ctgan13.save('ctgan_meso_sex.pkl')\n",
        "\n",
        "elif DATASET_NAME == 'SURGICAL_SEX':\n",
        "    TARGET_COL = 'complication'\n",
        "    PRIV_FEATURE = 'gender'\n",
        "    PRIV_VALUE_FEATURE = 0 #in this dataset, target = 1 is unfavorable\n",
        "    data = pd.read_csv('Data/Kaggle_Surgical-deepnet.csv')\n",
        "    PRIV_GROUP = 1 # females\n",
        "    feature_columns = ['bmi', 'Age', 'asa_status', 'baseline_cancer', 'baseline_charlson', 'baseline_cvd', 'baseline_dementia',\n",
        "                       'baseline_diabetes', 'baseline_digestive', 'baseline_osteoart', 'baseline_psych', 'baseline_pulmonary',\n",
        "                       'ahrq_ccs', 'ccsComplicationRate', 'ccsMort30Rate', 'complication_rsi', 'dow', 'gender', 'hour', 'month',\n",
        "                       'moonphase', 'mort30', 'mortality_rsi', 'race']\n",
        "    CATEGORICAL = ['asa_status', 'baseline_cancer', 'baseline_charlson', 'baseline_cvd', 'baseline_dementia',\n",
        "                       'baseline_diabetes', 'baseline_digestive', 'baseline_osteoart', 'baseline_psych', 'baseline_pulmonary',\n",
        "                     'month','dow','moonphase', 'mort30','race']\n",
        "        #CTGAN\n",
        "    metadata14 = SingleTableMetadata()\n",
        "    metadata14.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan14 = CTGANSynthesizer(metadata14, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan14.fit(data[feature_columns])\n",
        "    ctgan14.save('ctgan_surgical_sex.pkl')\n",
        "elif DATASET_NAME == 'SURGICAL_AGE':\n",
        "    TARGET_COL = 'complication'\n",
        "    PRIV_FEATURE = 'Age'\n",
        "    PRIV_VALUE_FEATURE = 0 #in this dataset, target = 1 is unfavorable\n",
        "    data = pd.read_csv('Data/Kaggle_Surgical-deepnet.csv')\n",
        "    data['Age'] = np.where(data['Age'] < 65, 0, 1)\n",
        "    PRIV_GROUP = 1 # young\n",
        "    feature_columns = ['bmi', 'Age', 'asa_status', 'baseline_cancer', 'baseline_charlson', 'baseline_cvd', 'baseline_dementia',\n",
        "                       'baseline_diabetes', 'baseline_digestive', 'baseline_osteoart', 'baseline_psych', 'baseline_pulmonary',\n",
        "                       'ahrq_ccs', 'ccsComplicationRate', 'ccsMort30Rate', 'complication_rsi', 'dow', 'gender', 'hour', 'month',\n",
        "                       'moonphase', 'mort30', 'mortality_rsi', 'race']\n",
        "    CATEGORICAL = ['asa_status','gender', 'baseline_cancer', 'baseline_charlson', 'baseline_cvd', 'baseline_dementia',\n",
        "                       'baseline_diabetes', 'baseline_digestive', 'baseline_osteoart', 'baseline_psych', 'baseline_pulmonary',\n",
        "                     'month','dow','moonphase', 'mort30','race']\n",
        "        #CTGAN\n",
        "    metadata15 = SingleTableMetadata()\n",
        "    metadata15.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan15 = CTGANSynthesizer(metadata15, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan15.fit(data[feature_columns])\n",
        "    ctgan15.save('ctgan_surgical_age.pkl')\n",
        "\n",
        "elif DATASET_NAME == 'DUTCH_SEX':\n",
        "    data = pd.read_csv('Data/dutch_census_2001.csv')\n",
        "    TARGET_COL = 'occupation'\n",
        "    PRIV_FEATURE = 'sex'\n",
        "    PRIV_VALUE_FEATURE = 1 # in this dataset, target=0 is unfavorable\n",
        "    data['sex'] = np.where(data['sex'] == 1, 0, 1) # convert 0 to males and 1 to females\n",
        "    data['occupation'] = np.where(data['occupation'] == '2_1', 0, 1)\n",
        "    PRIV_GROUP = 0 # male\n",
        "    feature_columns = ['sex', 'age', 'household_position', 'household_size', 'prev_residence_place', 'citizenship', 'country_birth',\n",
        "                       'edu_level', 'economic_status', 'cur_eco_activity', 'Marital_status']\n",
        "    CATEGORICAL = ['age', 'household_position', 'household_size', 'citizenship', 'country_birth',\n",
        "                  'edu_level', 'economic_status', 'cur_eco_activity', 'Marital_status']\n",
        "\n",
        "\n",
        "    # CTGAN\n",
        "    metadata16 = SingleTableMetadata()\n",
        "    metadata16.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan16 = CTGANSynthesizer(metadata16, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan16.fit(data[feature_columns])\n",
        "    ctgan16.save('ctgan_dutch_sex.pkl')\n",
        "\n",
        "elif DATASET_NAME == 'LAW_SEX':\n",
        "    data = pd.read_csv('Data/law_school_clean.csv')\n",
        "    TARGET_COL = 'pass_bar'\n",
        "    PRIV_FEATURE = 'male'\n",
        "    PRIV_VALUE_FEATURE = 1 # in this dataset, target = 0 is unfavorable\n",
        "    PRIV_GROUP = 1 # male\n",
        "    feature_columns = ['decile1b', 'decile3', 'lsat', 'ugpa', 'zfygpa', 'zgpa', 'fulltime', 'fam_inc', 'male', 'tier', 'race']\n",
        "    CATEGORICAL = ['fam_inc', 'tier', 'race']\n",
        "    # CTGAN\n",
        "    metadata17 = SingleTableMetadata()\n",
        "    metadata17.detect_from_dataframe(data=data[feature_columns])\n",
        "    ctgan17 = CTGANSynthesizer(metadata17, verbose=True, epochs=100 ,embedding_dim=32,generator_dim=(256,128,64,32),discriminator_dim=(256,128,64,32), discriminator_lr=5e-6,generator_lr=5e-6)\n",
        "\n",
        "    ctgan17.fit(data[feature_columns])\n",
        "    ctgan17.save('ctgan_law_sex.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6h_MiBA7m2U"
      },
      "source": [
        "### prepare datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JESxN5yQ7m2X"
      },
      "source": [
        "# PreProcessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iPG5h58L7m2X"
      },
      "outputs": [],
      "source": [
        "# Feature Selection\n",
        "\n",
        "#dataset for adverserial validaiton of the privileged feature\n",
        "priv_feature_columns = feature_columns.copy()\n",
        "#priv_feature_columns.append(TARGET_COL)\n",
        "priv_feature_columns.remove(PRIV_FEATURE)\n",
        "\n",
        "priv_data = data[priv_feature_columns].copy()\n",
        "priv_y = data[PRIV_FEATURE].copy()\n",
        "\n",
        "# dataset for training\n",
        "y = data[TARGET_COL]\n",
        "data = data[feature_columns]\n",
        "\n",
        "import category_encoders as ce\n",
        "encoder = ce.TargetEncoder(cols=CATEGORICAL)\n",
        "\n",
        "encoder.fit(data, y)\n",
        "data = encoder.transform(data)\n",
        "\n",
        "\n",
        "\n",
        "encoder1 = ce.TargetEncoder(cols=CATEGORICAL)\n",
        "encoder1.fit(priv_data, priv_y)\n",
        "priv_data = encoder1.transform(priv_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nGKKFj627m2Y"
      },
      "outputs": [],
      "source": [
        "def print_metrics(y_gt, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_gt, y_pred).ravel()\n",
        "    print('conf matrix:\\n ', confusion_matrix(y_gt, y_pred) ,\n",
        "          '\\naccuracy: ', (tp+tn)/(tp+tn+fn+fp),\n",
        "          'precision: ', tp/(tp+fp),\n",
        "          'recall: ', tp/(tp+fn),\n",
        "          'fpr: ', fp/(fp+tn),\n",
        "          'tpr: ', tp /(tp + fn),\n",
        "          'fn+fp', fn+fp)\n",
        "    #returm fpr, tpr, accuracy\n",
        "    return fp/(fp+tn), tp /(tp + fn), (tp+tn)/(tp+tn+fn+fp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "j0OgNuue7m2Y"
      },
      "outputs": [],
      "source": [
        "# bias metric - equal opportunity difference\n",
        "def opportunity_diff_tpr(tpr1, tpr2):\n",
        "    return abs(tpr1-tpr2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KDvzYbTt7m2Y"
      },
      "outputs": [],
      "source": [
        "# bias metric - equal opportunity difference\n",
        "def opportunity_diff_fpr(fpr1, fpr2):\n",
        "    return abs(fpr1-fpr2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MXWR0SB57m2Z"
      },
      "outputs": [],
      "source": [
        "# bias metric - avarage absolute odds difference\n",
        "def odds_diff(tpr1, tpr2, fpr1, fpr2):\n",
        "    return 0.5*(abs(tpr2-tpr1) + abs(fpr2-fpr1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UoSLSRd37m2Z"
      },
      "outputs": [],
      "source": [
        "# bias metric - statistical parity difference\n",
        "def parity_diff(y_pred_0, y_pred_1):\n",
        "    if PRIV_GROUP ==1:\n",
        "        return len(y_pred_0)/(len(y_pred_0)+len(y_pred_1)) - len(y_pred_1)/(len(y_pred_1)+len(y_pred_0))\n",
        "    else:\n",
        "        return len(y_pred_1)/(len(y_pred_0)+len(y_pred_1)) - len(y_pred_0)/(len(y_pred_1)+len(y_pred_0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4xTXhVXZ7m2Z"
      },
      "outputs": [],
      "source": [
        "# bias metric - Disparate impact\n",
        "def disparate_impact(y_pred_0, y_pred_1):\n",
        "    if PRIV_VALUE_FEATURE == 1:\n",
        "        rate_0 = sum(y_pred_0) / len(y_pred_0) if len(y_pred_0) > 0 else 0\n",
        "        rate_1 = sum(y_pred_1) / len(y_pred_1) if len(y_pred_1) > 0 else 0\n",
        "    else:\n",
        "        rate_0 = sum(1 - y for y in y_pred_0) / len(y_pred_0) if len(y_pred_0) > 0 else 0\n",
        "        rate_1 = sum(1 - y for y in y_pred_1) / len(y_pred_1) if len(y_pred_1) > 0 else 0\n",
        "\n",
        "    if PRIV_GROUP == 1:\n",
        "        return rate_0 / rate_1 if rate_1 > 0 else 0\n",
        "    else:\n",
        "        return rate_1 / rate_0 if rate_0 > 0 else 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "c1jlZv7A7m2Z"
      },
      "outputs": [],
      "source": [
        "# calculate the bias of divided dataset by the privileged feature\n",
        "def calc_bias(data,y, priv_feature,y_pred, experiment_text):\n",
        "    data_full =  pd.concat([data, y], axis=1)\n",
        "    data_full['y_pred'] = y_pred\n",
        "\n",
        "    label = TARGET_COL\n",
        "    print('performance for whole ds:'+ experiment_text)\n",
        "    fpr, tpr, acc = print_metrics(data_full[TARGET_COL], data_full['y_pred'] )\n",
        "\n",
        "    feature_cat_list = list(data[priv_feature].unique())\n",
        "    #print(feature_cat_list)\n",
        "    valid_cat0 = data_full[data_full[priv_feature]==feature_cat_list[0]]\n",
        "    valid_cat1 = data_full[data_full[priv_feature]==feature_cat_list[1]]\n",
        "    print('performance for 0 sub-group:')\n",
        "    fpr_0, tpr_0 , acc_0 = print_metrics(valid_cat0[TARGET_COL], valid_cat0['y_pred'])\n",
        "    print('performance for 1 sub-group:')\n",
        "\n",
        "    fpr_1, tpr_1, acc_1 = print_metrics(valid_cat1[TARGET_COL], valid_cat1['y_pred'])\n",
        "    op_diff = opportunity_diff_tpr(tpr_0, tpr_1)\n",
        "    op_diff_fpr = opportunity_diff_fpr(fpr_0, fpr_1)\n",
        "    od_diff = odds_diff(tpr_0, tpr_1, fpr_0, fpr_1)\n",
        "    print('bias metrics:')\n",
        "\n",
        "    print('avarage absolute odds difference: (close to 0)',od_diff)\n",
        "    di = disparate_impact(valid_cat0['y_pred'].astype(int),valid_cat1['y_pred'].astype(int))\n",
        "\n",
        "    return (op_diff,op_diff_fpr, od_diff, acc,fpr_0, tpr_0, fpr_1, tpr_1, di)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svw1MY-x7m2Z"
      },
      "source": [
        "# TTA implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NxNw_vf7m2a"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmJYqD8G7m2a"
      },
      "source": [
        "## General baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfStw4xE7m2f",
        "outputId": "0dbb6a68-4019-4b4c-c792-58d94b455812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "performance for whole ds:subexperiment - baseline wo/TTA model:0\n",
            "conf matrix:\n",
            "  [[511  35]\n",
            " [ 82 172]] \n",
            "accuracy:  0.85375 precision:  0.8309178743961353 recall:  0.6771653543307087 fpr:  0.0641025641025641 tpr:  0.6771653543307087 fn+fp 117\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[226  28]\n",
            " [ 43 108]] \n",
            "accuracy:  0.8246913580246914 precision:  0.7941176470588235 recall:  0.7152317880794702 fpr:  0.11023622047244094 tpr:  0.7152317880794702 fn+fp 71\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[285   7]\n",
            " [ 39  64]] \n",
            "accuracy:  0.8835443037974684 precision:  0.9014084507042254 recall:  0.6213592233009708 fpr:  0.023972602739726026 tpr:  0.6213592233009708 fn+fp 46\n",
            "bias metrics:\n",
            "avarage absolute odds difference: (close to 0) 0.09006809125560714\n",
            "performance for whole ds:subexperiment - baseline wo/TTA model:1\n",
            "conf matrix:\n",
            "  [[504  42]\n",
            " [ 77 177]] \n",
            "accuracy:  0.85125 precision:  0.8082191780821918 recall:  0.6968503937007874 fpr:  0.07692307692307693 tpr:  0.6968503937007874 fn+fp 119\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[256  12]\n",
            " [ 46  66]] \n",
            "accuracy:  0.8473684210526315 precision:  0.8461538461538461 recall:  0.5892857142857143 fpr:  0.04477611940298507 tpr:  0.5892857142857143 fn+fp 58\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[248  30]\n",
            " [ 31 111]] \n",
            "accuracy:  0.8547619047619047 precision:  0.7872340425531915 recall:  0.7816901408450704 fpr:  0.1079136690647482 tpr:  0.7816901408450704 fn+fp 61\n",
            "bias metrics:\n",
            "avarage absolute odds difference: (close to 0) 0.1277709881105596\n",
            "performance for whole ds:subexperiment - baseline wo/TTA model:2\n",
            "conf matrix:\n",
            "  [[503  44]\n",
            " [ 67 186]] \n",
            "accuracy:  0.86125 precision:  0.808695652173913 recall:  0.7351778656126482 fpr:  0.08043875685557587 tpr:  0.7351778656126482 fn+fp 111\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[235  17]\n",
            " [ 33  70]] \n",
            "accuracy:  0.8591549295774648 precision:  0.8045977011494253 recall:  0.6796116504854369 fpr:  0.06746031746031746 tpr:  0.6796116504854369 fn+fp 50\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[268  27]\n",
            " [ 34 116]] \n",
            "accuracy:  0.8629213483146068 precision:  0.8111888111888111 recall:  0.7733333333333333 fpr:  0.09152542372881356 tpr:  0.7733333333333333 fn+fp 61\n",
            "bias metrics:\n",
            "avarage absolute odds difference: (close to 0) 0.05889339455819625\n",
            "performance for whole ds:subexperiment - baseline wo/TTA model:3\n",
            "conf matrix:\n",
            "  [[511  36]\n",
            " [ 80 173]] \n",
            "accuracy:  0.855 precision:  0.8277511961722488 recall:  0.6837944664031621 fpr:  0.06581352833638025 tpr:  0.6837944664031621 fn+fp 116\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[263  16]\n",
            " [ 37  67]] \n",
            "accuracy:  0.8616187989556136 precision:  0.8072289156626506 recall:  0.6442307692307693 fpr:  0.05734767025089606 tpr:  0.6442307692307693 fn+fp 53\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[248  20]\n",
            " [ 43 106]] \n",
            "accuracy:  0.8489208633093526 precision:  0.8412698412698413 recall:  0.7114093959731543 fpr:  0.07462686567164178 tpr:  0.7114093959731543 fn+fp 63\n",
            "bias metrics:\n",
            "avarage absolute odds difference: (close to 0) 0.042228911081565394\n",
            "performance for whole ds:subexperiment - baseline wo/TTA model:4\n",
            "conf matrix:\n",
            "  [[498  49]\n",
            " [ 75 178]] \n",
            "accuracy:  0.845 precision:  0.7841409691629956 recall:  0.7035573122529645 fpr:  0.08957952468007313 tpr:  0.7035573122529645 fn+fp 124\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[254  28]\n",
            " [ 40 118]] \n",
            "accuracy:  0.8454545454545455 precision:  0.8082191780821918 recall:  0.7468354430379747 fpr:  0.09929078014184398 tpr:  0.7468354430379747 fn+fp 68\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[244  21]\n",
            " [ 35  60]] \n",
            "accuracy:  0.8444444444444444 precision:  0.7407407407407407 recall:  0.631578947368421 fpr:  0.07924528301886792 tpr:  0.631578947368421 fn+fp 56\n",
            "bias metrics:\n",
            "avarage absolute odds difference: (close to 0) 0.06765099639626485\n"
          ]
        }
      ],
      "source": [
        "\n",
        "cv = StratifiedKFold(n_splits=NFOLDS, random_state=1234, shuffle=True)\n",
        "results = pd.DataFrame(columns=['training_score', 'test_score'])\n",
        "\n",
        "if EXP =='RF':\n",
        "    clf = RandomForestClassifier(random_state=0, min_samples_leaf = 7)#max_depth=50, , min_samples_leaf = 7\n",
        "elif EXP == 'XGB':\n",
        "    clf = XGBClassifier(max_depth=5, n_estimators=40, subsample=0.9, learning_rate=0.1, random_state = 142)\n",
        "elif EXP == 'NN':\n",
        "    clf = MLPClassifier(hidden_layer_sizes = 157, solver = 'adam', learning_rate = 'adaptive', random_state = 142)\n",
        "\n",
        "else:\n",
        "    clf = LogisticRegression(random_state = 142, n_jobs = -1)\n",
        "\n",
        "fprs, tprs, scores, op,op_f,  od , acc , fpr_0, tpr_0, fpr_1, tpr_1, d_i = [], [], [], [],[], [], [], [], [], [], [], []\n",
        "\n",
        "start_time = datetime.now()\n",
        "for (train, test), i in zip(cv.split(data, y), range(5)):\n",
        "    clf.fit(data.iloc[train], y.iloc[train])\n",
        "    #_, _, auc_score_train = compute_roc_auc(train)\n",
        "    #fpr, tpr, auc_score = compute_roc_auc(test)\n",
        "    #scores.append((auc_score_train, auc_score))\n",
        "    # fprs.append(fpr)\n",
        "    # tprs.append(tpr)\n",
        "    y_pred = clf.predict(data.iloc[test])\n",
        "    o_p, o_p_fpr, o_d , acc_ , fpr_0_, tpr_0_, fpr_1_, tpr_1_, d_i_ = calc_bias(data.iloc[test],  y.iloc[test], PRIV_FEATURE,y_pred, 'subexperiment - baseline wo/TTA'+' model:'+str(i))\n",
        "    acc.append(acc_)\n",
        "    op.append(o_p)\n",
        "    op_f.append(o_p_fpr)\n",
        "    od.append(o_d)\n",
        "    fpr_0.append(fpr_0_)\n",
        "    tpr_0.append(tpr_0_)\n",
        "    fpr_1.append(fpr_1_)\n",
        "    tpr_1.append(tpr_1_)\n",
        "    d_i.append(d_i_)\n",
        "time_elapsed_baseline = datetime.now() - start_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmFu95Mp7m2f",
        "outputId": "f6617e13-aa0c-4b2a-aece-d9f8c6ab0dc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPR: 0.07582222154569669 0.07545676884475949\n",
            "TPR: 0.675039073023873 0.70387420816419\n",
            "beacause of tpr:\n",
            "group z = 0 experiences more False Negatives relative to class 0\n",
            "because of fpr:\n",
            "group z = 0 experiences more False Positives relative to class 1\n"
          ]
        }
      ],
      "source": [
        "print('FPR:' , np.mean(fpr_0),np.mean(fpr_1) )\n",
        "print('TPR:', np.mean(tpr_0), np.mean(tpr_1))\n",
        "print('beacause of tpr:')\n",
        "if np.mean(tpr_1) > np.mean(tpr_0):\n",
        "    print ('group z = 0 experiences more False Negatives relative to class 0')\n",
        "else:\n",
        "    print ('group z = 1 experiences more False Negatives relative to class 0')\n",
        "print('because of fpr:')\n",
        "if np.mean(fpr_1) > np.mean(fpr_0):\n",
        "    print('group z = 1 experiences more False Positives relative to class 1')\n",
        "else:\n",
        "    print('group z = 0 experiences more False Positives relative to class 1')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P42G5RiU7m2f"
      },
      "source": [
        "## Baseline using Reject Option"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb-gYMyP7m2f",
        "outputId": "360106b7-e85b-4b34-9cf2-c568e98a7658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "performance for whole ds:subexperiment - baseline THO model:0\n",
            "conf matrix:\n",
            "  [[505  41]\n",
            " [ 83 171]] \n",
            "accuracy:  0.845 precision:  0.8066037735849056 recall:  0.6732283464566929 fpr:  0.07509157509157509 tpr:  0.6732283464566929 fn+fp 124\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[226  28]\n",
            " [ 43 108]] \n",
            "accuracy:  0.8246913580246914 precision:  0.7941176470588235 recall:  0.7152317880794702 fpr:  0.11023622047244094 tpr:  0.7152317880794702 fn+fp 71\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[279  13]\n",
            " [ 40  63]] \n",
            "accuracy:  0.8658227848101265 precision:  0.8289473684210527 recall:  0.6116504854368932 fpr:  0.04452054794520548 tpr:  0.6116504854368932 fn+fp 53\n",
            "bias metrics:\n",
            "avarage absolute odds difference: (close to 0) 0.08464848758490626\n",
            "performance for whole ds:subexperiment - baseline THO model:1\n",
            "conf matrix:\n",
            "  [[501  45]\n",
            " [ 71 183]] \n",
            "accuracy:  0.855 precision:  0.8026315789473685 recall:  0.7204724409448819 fpr:  0.08241758241758242 tpr:  0.7204724409448819 fn+fp 116\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[253  15]\n",
            " [ 40  72]] \n",
            "accuracy:  0.8552631578947368 precision:  0.8275862068965517 recall:  0.6428571428571429 fpr:  0.055970149253731345 tpr:  0.6428571428571429 fn+fp 55\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[248  30]\n",
            " [ 31 111]] \n",
            "accuracy:  0.8547619047619047 precision:  0.7872340425531915 recall:  0.7816901408450704 fpr:  0.1079136690647482 tpr:  0.7816901408450704 fn+fp 61\n",
            "bias metrics:\n",
            "avarage absolute odds difference: (close to 0) 0.09538825889947217\n",
            "performance for whole ds:subexperiment - baseline THO model:2\n",
            "conf matrix:\n",
            "  [[502  45]\n",
            " [ 66 187]] \n",
            "accuracy:  0.86125 precision:  0.8060344827586207 recall:  0.7391304347826086 fpr:  0.08226691042047532 tpr:  0.7391304347826086 fn+fp 111\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[234  18]\n",
            " [ 32  71]] \n",
            "accuracy:  0.8591549295774648 precision:  0.797752808988764 recall:  0.6893203883495146 fpr:  0.07142857142857142 tpr:  0.6893203883495146 fn+fp 50\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[268  27]\n",
            " [ 34 116]] \n",
            "accuracy:  0.8629213483146068 precision:  0.8111888111888111 recall:  0.7733333333333333 fpr:  0.09152542372881356 tpr:  0.7733333333333333 fn+fp 61\n",
            "bias metrics:\n",
            "avarage absolute odds difference: (close to 0) 0.05205489864203043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "performance for whole ds:subexperiment - baseline THO model:3\n",
            "conf matrix:\n",
            "  [[501  46]\n",
            " [ 75 178]] \n",
            "accuracy:  0.84875 precision:  0.7946428571428571 recall:  0.7035573122529645 fpr:  0.08409506398537477 tpr:  0.7035573122529645 fn+fp 121\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[253  26]\n",
            " [ 32  72]] \n",
            "accuracy:  0.8485639686684073 precision:  0.7346938775510204 recall:  0.6923076923076923 fpr:  0.0931899641577061 tpr:  0.6923076923076923 fn+fp 58\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[248  20]\n",
            " [ 43 106]] \n",
            "accuracy:  0.8489208633093526 precision:  0.8412698412698413 recall:  0.7114093959731543 fpr:  0.07462686567164178 tpr:  0.7114093959731543 fn+fp 63\n",
            "bias metrics:\n",
            "avarage absolute odds difference: (close to 0) 0.01883240107576318\n",
            "performance for whole ds:subexperiment - baseline THO model:4\n",
            "conf matrix:\n",
            "  [[497  50]\n",
            " [ 76 177]] \n",
            "accuracy:  0.8425 precision:  0.7797356828193832 recall:  0.6996047430830039 fpr:  0.09140767824497258 tpr:  0.6996047430830039 fn+fp 126\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[254  28]\n",
            " [ 40 118]] \n",
            "accuracy:  0.8454545454545455 precision:  0.8082191780821918 recall:  0.7468354430379747 fpr:  0.09929078014184398 tpr:  0.7468354430379747 fn+fp 68\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[243  22]\n",
            " [ 36  59]] \n",
            "accuracy:  0.8388888888888889 precision:  0.7283950617283951 recall:  0.6210526315789474 fpr:  0.0830188679245283 tpr:  0.6210526315789474 fn+fp 58\n",
            "bias metrics:\n",
            "avarage absolute odds difference: (close to 0) 0.07102736183817146\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "def apply_reject_option_classification(predictions, protected_attribute, threshold=0.5, uncertainty_range=0.05):\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Apply the reject option to mitigate bias in model predictions.\n",
        "    Parameters:\n",
        "    - predictions: array-like, model predictions (probabilities) before applying the reject option.\n",
        "    - protected_attribute: array-like, the protected attribute based on which bias might occur (0 or 1).\n",
        "    - threshold: float, the decision threshold for classification.\n",
        "    - uncertainty_range: float, defines the region of uncertainty around the threshold.\n",
        "\n",
        "    Returns:\n",
        "    - corrected_predictions: array, the predictions after applying the reject option for bias mitigation.\n",
        "    \"\"\"\n",
        "    global flip_counter\n",
        "\n",
        "    # Initialize corrected predictions with the original predictions\n",
        "    corrected_predictions = np.zeros(predictions.shape)\n",
        "    decision_boundary_lower = threshold - uncertainty_range\n",
        "    decision_boundary_upper = threshold + uncertainty_range\n",
        "    for i, pred in enumerate(predictions):\n",
        "          # Check if prediction falls within the region of uncertainty\n",
        "          if decision_boundary_lower < pred < decision_boundary_upper:\n",
        "              # Apply mitigation strategy: Here, we flip the decision if it correlates with the protected attribute\n",
        "              # This is a simple strategy and can be replaced with more sophisticated ones\n",
        "              if protected_attribute[i] != PRIV_GROUP:\n",
        "                  if predictions[i] != PRIV_VALUE_FEATURE:\n",
        "                    corrected_predictions[i] = 1 - (pred > threshold) # change prediction\n",
        "                    flip_counter += 1\n",
        "                  else: # dont change prediction\n",
        "                    corrected_predictions[i] = pred > threshold\n",
        "              else:\n",
        "                  corrected_predictions[i] = pred > threshold\n",
        "          else:\n",
        "              # Outside the region of uncertainty, keep the original decision\n",
        "              corrected_predictions[i] = pred > threshold\n",
        "    return corrected_predictions\n",
        "\n",
        "\n",
        "cv = StratifiedKFold(n_splits=NFOLDS, random_state=1234, shuffle=True)\n",
        "results = pd.DataFrame(columns=['training_score', 'test_score'])\n",
        "\n",
        "if EXP =='RF':\n",
        "    clf = RandomForestClassifier(random_state=0, min_samples_leaf = 7)\n",
        "elif EXP == 'XGB':\n",
        "    clf = XGBClassifier(max_depth=5, n_estimators=40, subsample=0.9, learning_rate=0.1, random_state = 142)\n",
        "elif EXP == 'NN':\n",
        "    clf = MLPClassifier(hidden_layer_sizes = 157, solver = 'adam', learning_rate = 'adaptive', random_state = 142)\n",
        "else:\n",
        "    clf = LogisticRegression(random_state = 142)\n",
        "\n",
        "fprs, tprs, scores, op_tho,op_f_tho, od_tho, acc_tho, fpr_0_tho, tpr_0_tho, fpr_1_tho, tpr_1_tho, d_i_tho = [], [], [], [],[], [], [], [], [], [], [], []\n",
        "flip_counter = 0\n",
        "start_time = datetime.now()\n",
        "for (train, test), i in zip(cv.split(data, y), range(5)):\n",
        "    clf.fit(data.iloc[train], y.iloc[train].astype(int))\n",
        "\n",
        "    y_pred_tho = []\n",
        "    reg_preds = clf.predict_proba(data.iloc[test])\n",
        "    y_pred_tho = apply_reject_option_classification(reg_preds[:,1], data.iloc[test][PRIV_FEATURE].values)\n",
        "    o_p_tho,o_p_tho_fpr, o_d_tho, acc_tho_, fpr_0_tho_, tpr_0_tho_, fpr_1_tho_, tpr_1_tho_, d_i_tho_ = calc_bias(data.iloc[test],  y.iloc[test], PRIV_FEATURE,y_pred_tho, 'subexperiment - baseline THO'+' model:'+str(i))\n",
        "    op_tho.append(o_p_tho)\n",
        "    op_f_tho.append(o_p_tho_fpr)\n",
        "    od_tho.append(o_d_tho)\n",
        "    acc_tho.append(acc_tho_)\n",
        "\n",
        "    fpr_0_tho.append(fpr_0_tho_)\n",
        "    tpr_0_tho.append(tpr_0_tho_)\n",
        "    fpr_1_tho.append(fpr_1_tho_)\n",
        "    tpr_1_tho.append(tpr_1_tho_)\n",
        "    d_i_tho.append(d_i_tho_)\n",
        "time_elapsed_tho = datetime.now() - start_time\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        },
        "id": "ZcwWrcQR7m2g",
        "outputId": "68d54f79-284d-484f-a03c-4c54ebb55adf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\seffi\\OneDrive\\Public\\Documents\\PostDoc\\BiasG\\wandb\\run-20250114_121611-teyupy0y</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/teyupy0y' target=\"_blank\">winter-cherry-52</a></strong> to <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/teyupy0y' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/teyupy0y</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "baseline with Reject Option\n",
            "tpr0:  0.6973104909263589  tpr1:  0.6998271974334798  delta:  0.0025167065071208805\n",
            "fpr0:  0.08602313709085876 fpr1:  0.08032107486698746  delta:  0.005702062223871304\n",
            "equal opportunity for tpr:  0.0942623521477625\n",
            "equal opportunity for fpr:  0.03451821106837488\n",
            "avarage absolute odds difference:  0.0643902816080687\n",
            "accuracy:  0.8504999999999999\n",
            "Time:  0:00:00.258315\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DI</td><td>▁</td></tr><tr><td>DI_var</td><td>▁</td></tr><tr><td>acc_var</td><td>▁</td></tr><tr><td>accuracy</td><td>▁</td></tr><tr><td>avarge odd</td><td>▁</td></tr><tr><td>dFPR</td><td>▁</td></tr><tr><td>dTPR</td><td>▁</td></tr><tr><td>flips</td><td>▁</td></tr><tr><td>odd_var</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DI</td><td>1.03601</td></tr><tr><td>DI_var</td><td>0.12182</td></tr><tr><td>acc_var</td><td>5e-05</td></tr><tr><td>accuracy</td><td>0.8505</td></tr><tr><td>avarge odd</td><td>0.06439</td></tr><tr><td>dFPR</td><td>0.03452</td></tr><tr><td>dTPR</td><td>0.09426</td></tr><tr><td>dataset</td><td>RECRUIT_SEX</td></tr><tr><td>experiment</td><td>baseline with Reject...</td></tr><tr><td>flips</td><td>133</td></tr><tr><td>model</td><td>RF</td></tr><tr><td>odd_var</td><td>0.00073</td></tr><tr><td>time</td><td>0:00:00.258315</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">winter-cherry-52</strong> at: <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/teyupy0y' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/teyupy0y</a><br> View project at: <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20250114_121611-teyupy0y\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "experiment = 'baseline with Reject Option'\n",
        "run = wandb.init(project='BiasGuardRF1', reinit = True)\n",
        "print(experiment)\n",
        "print('tpr0: ', np.mean(tpr_0_tho) , ' tpr1: ', np.mean(tpr_1_tho), ' delta: ', abs(np.mean(tpr_0_tho) - np.mean(tpr_1_tho)))\n",
        "print('fpr0: ', np.mean(fpr_0_tho), 'fpr1: ', np.mean(fpr_1_tho), ' delta: ', abs(np.mean(fpr_0_tho) - np.mean(fpr_1_tho)))\n",
        "print('equal opportunity for tpr: ',np.mean(op_tho))\n",
        "print('equal opportunity for fpr: ',np.mean(op_f_tho))\n",
        "print('avarage absolute odds difference: ',np.mean(od_tho))\n",
        "print('accuracy: ', np.mean(acc_tho))\n",
        "print('Time: ',time_elapsed_tho)\n",
        "wandb.log({'dataset' : DATASET_NAME, 'model' : EXP, 'experiment' : experiment,\n",
        "            'accuracy' : np.mean(acc_tho), 'acc_var': np.var(acc_tho), 'dTPR' : np.mean(op_tho), 'dFPR':np.mean(op_f_tho),\n",
        "            'avarge odd' : np.mean(od_tho), 'odd_var': np.var(od_tho), 'DI':np.mean(d_i_tho), 'DI_var': np.var(d_i_tho), 'flips': flip_counter, 'time' : str(time_elapsed_tho) }, step=0)\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9BvTDuy7m2g"
      },
      "source": [
        "## Baseline using Thresholds optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_0xKn60l7m2g",
        "outputId": "2c8176ee-f334-4c59-cfd9-6a11449d65a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "performance for whole ds:subexperiment - baseline THO model:0\n",
            "conf matrix:\n",
            "  [[498  48]\n",
            " [ 75 179]] \n",
            "accuracy:  0.84625 precision:  0.788546255506608 recall:  0.7047244094488189 fpr:  0.08791208791208792 tpr:  0.7047244094488189 fn+fp 123\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[235  19]\n",
            " [ 54  97]] \n",
            "accuracy:  0.8197530864197531 precision:  0.8362068965517241 recall:  0.6423841059602649 fpr:  0.07480314960629922 tpr:  0.6423841059602649 fn+fp 73\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[263  29]\n",
            " [ 21  82]] \n",
            "accuracy:  0.8734177215189873 precision:  0.7387387387387387 recall:  0.7961165048543689 fpr:  0.09931506849315068 tpr:  0.7961165048543689 fn+fp 50\n",
            "bias metrics:\n",
            "avarage absolute odds difference: (close to 0) 0.08912215889047775\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "performance for whole ds:subexperiment - baseline THO model:1\n",
            "conf matrix:\n",
            "  [[476  70]\n",
            " [ 62 192]] \n",
            "accuracy:  0.835 precision:  0.732824427480916 recall:  0.7559055118110236 fpr:  0.1282051282051282 tpr:  0.7559055118110236 fn+fp 132\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[226  42]\n",
            " [ 26  86]] \n",
            "accuracy:  0.8210526315789474 precision:  0.671875 recall:  0.7678571428571429 fpr:  0.15671641791044777 tpr:  0.7678571428571429 fn+fp 68\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[250  28]\n",
            " [ 36 106]] \n",
            "accuracy:  0.8476190476190476 precision:  0.7910447761194029 recall:  0.7464788732394366 fpr:  0.10071942446043165 tpr:  0.7464788732394366 fn+fp 64\n",
            "bias metrics:\n",
            "avarage absolute odds difference: (close to 0) 0.0386876315338612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "performance for whole ds:subexperiment - baseline THO model:2\n",
            "conf matrix:\n",
            "  [[467  80]\n",
            " [ 62 191]] \n",
            "accuracy:  0.8225 precision:  0.7047970479704797 recall:  0.7549407114624506 fpr:  0.14625228519195613 tpr:  0.7549407114624506 fn+fp 142\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[197  55]\n",
            " [ 18  85]] \n",
            "accuracy:  0.7943661971830986 precision:  0.6071428571428571 recall:  0.8252427184466019 fpr:  0.21825396825396826 tpr:  0.8252427184466019 fn+fp 73\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[270  25]\n",
            " [ 44 106]] \n",
            "accuracy:  0.8449438202247191 precision:  0.8091603053435115 recall:  0.7066666666666667 fpr:  0.0847457627118644 tpr:  0.7066666666666667 fn+fp 69\n",
            "bias metrics:\n",
            "avarage absolute odds difference: (close to 0) 0.12604212866101955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "performance for whole ds:subexperiment - baseline THO model:3\n",
            "conf matrix:\n",
            "  [[487  60]\n",
            " [ 70 183]] \n",
            "accuracy:  0.8375 precision:  0.7530864197530864 recall:  0.7233201581027668 fpr:  0.10968921389396709 tpr:  0.7233201581027668 fn+fp 130\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[236  43]\n",
            " [ 17  87]] \n",
            "accuracy:  0.8433420365535248 precision:  0.6692307692307692 recall:  0.8365384615384616 fpr:  0.15412186379928317 tpr:  0.8365384615384616 fn+fp 60\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[251  17]\n",
            " [ 53  96]] \n",
            "accuracy:  0.8321342925659473 precision:  0.8495575221238938 recall:  0.6442953020134228 fpr:  0.06343283582089553 tpr:  0.6442953020134228 fn+fp 70\n",
            "bias metrics:\n",
            "avarage absolute odds difference: (close to 0) 0.1414660937517132\n",
            "performance for whole ds:subexperiment - baseline THO model:4\n",
            "conf matrix:\n",
            "  [[493  54]\n",
            " [ 71 182]] \n",
            "accuracy:  0.84375 precision:  0.7711864406779662 recall:  0.7193675889328063 fpr:  0.09872029250457039 tpr:  0.7193675889328063 fn+fp 125\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[263  19]\n",
            " [ 48 110]] \n",
            "accuracy:  0.8477272727272728 precision:  0.8527131782945736 recall:  0.6962025316455697 fpr:  0.0673758865248227 tpr:  0.6962025316455697 fn+fp 67\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[230  35]\n",
            " [ 23  72]] \n",
            "accuracy:  0.8388888888888889 precision:  0.6728971962616822 recall:  0.7578947368421053 fpr:  0.1320754716981132 tpr:  0.7578947368421053 fn+fp 58\n",
            "bias metrics:\n",
            "avarage absolute odds difference: (close to 0) 0.06319589518491306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\seffi\\anaconda3\\envs\\kats\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "cv = StratifiedKFold(n_splits=NFOLDS, random_state=1234, shuffle=True)\n",
        "results = pd.DataFrame(columns=['training_score', 'test_score'])\n",
        "\n",
        "if EXP =='RF':\n",
        "    clf = RandomForestClassifier(random_state=0, min_samples_leaf = 7)\n",
        "elif EXP == 'XGB':\n",
        "    clf = XGBClassifier(max_depth=5, n_estimators=40, subsample=0.9, learning_rate=0.1, random_state = 142)\n",
        "elif EXP == 'NN':\n",
        "    clf = MLPClassifier(hidden_layer_sizes = 157, solver = 'adam', learning_rate = 'adaptive', random_state = 142)\n",
        "else:\n",
        "    clf = LogisticRegression(random_state = 142)\n",
        "\n",
        "flips = 0\n",
        "fprs, tprs, scores, op_tho,op_f_tho, od_tho, acc_tho, fpr_0_tho, tpr_0_tho, fpr_1_tho, tpr_1_tho, d_i_tho = [], [], [], [],[], [], [], [], [], [], [], []\n",
        "start_time = datetime.now()\n",
        "for (train, test), i in zip(cv.split(data, y), range(5)):\n",
        "    clf.fit(data.iloc[train], y.iloc[train].astype(int))\n",
        "\n",
        "    y_pred_tho = []\n",
        "    pre_optimized_preds = clf.predict_proba(data.iloc[test])[:, 1]\n",
        "    pre_optimized_preds_binary = (pre_optimized_preds > 0.5).astype(int) ### הוספתי את השורה הזאת\n",
        "    postprocess_est = ThresholdOptimizer(\n",
        "                       estimator=clf,\n",
        "                       predict_method='predict_proba')\n",
        "    postprocess_est.fit(data.iloc[train],  y.iloc[train].astype(int), sensitive_features=data.iloc[train][PRIV_FEATURE])\n",
        "    y_pred_tho = postprocess_est.predict(data.iloc[test], sensitive_features=data.iloc[test][PRIV_FEATURE])\n",
        "    flips += sum(pre_optimized_preds_binary != y_pred_tho) ### ופה שיניתי את הספירה של הפליפים\n",
        "    o_p_tho,o_p_tho_fpr, o_d_tho, acc_tho_, fpr_0_tho_, tpr_0_tho_, fpr_1_tho_, tpr_1_tho_, d_i_tho_ = calc_bias(data.iloc[test],  y.iloc[test], PRIV_FEATURE,y_pred_tho, 'subexperiment - baseline THO'+' model:'+str(i))\n",
        "    op_tho.append(o_p_tho)\n",
        "    op_f_tho.append(o_p_tho_fpr)\n",
        "    od_tho.append(o_d_tho)\n",
        "    acc_tho.append(acc_tho_)\n",
        "\n",
        "    fpr_0_tho.append(fpr_0_tho_)\n",
        "    tpr_0_tho.append(tpr_0_tho_)\n",
        "    fpr_1_tho.append(fpr_1_tho_)\n",
        "    tpr_1_tho.append(tpr_1_tho_)\n",
        "    d_i_tho.append(d_i_tho_)\n",
        "time_elapsed_tho = datetime.now() - start_time\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqByJch87m2h"
      },
      "source": [
        "## Bias mitigation using FairTTA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "4tzG7Ygo7m2h",
        "outputId": "f8f1051e-b482-48de-ef3b-95e36901b51f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\seffi\\OneDrive\\Public\\Documents\\PostDoc\\BiasG\\wandb\\run-20250114_121617-b22cc5ke</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/b22cc5ke' target=\"_blank\">glowing-bush-53</a></strong> to <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/b22cc5ke' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/b22cc5ke</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "baseline without TTA\n",
            "equal opportunity for tpr:  0.11248675931953811 0.0018291896375059896\n",
            "equal opportunity for fpr:  0.042158193241339195 0.0007641435047533319\n",
            "avarage absolute odds difference:  0.07732247628043865 0.0008744459883223454\n",
            "accuracy:  0.8532500000000001 2.7874999999999993e-05\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DI</td><td>▁</td></tr><tr><td>DI_var</td><td>▁</td></tr><tr><td>acc_var</td><td>▁</td></tr><tr><td>accuracy</td><td>▁</td></tr><tr><td>avarge odd</td><td>▁</td></tr><tr><td>dFPR</td><td>▁</td></tr><tr><td>dTPR</td><td>▁</td></tr><tr><td>odd_var</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DI</td><td>1.11089</td></tr><tr><td>DI_var</td><td>0.18287</td></tr><tr><td>acc_var</td><td>3e-05</td></tr><tr><td>accuracy</td><td>0.85325</td></tr><tr><td>avarge odd</td><td>0.07732</td></tr><tr><td>dFPR</td><td>0.04216</td></tr><tr><td>dTPR</td><td>0.11249</td></tr><tr><td>dataset</td><td>RECRUIT_SEX</td></tr><tr><td>experiment</td><td>baseline without TTA...</td></tr><tr><td>model</td><td>RF</td></tr><tr><td>odd_var</td><td>0.00087</td></tr><tr><td>time</td><td>0:00:00.243163</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">glowing-bush-53</strong> at: <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/b22cc5ke' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/b22cc5ke</a><br> View project at: <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20250114_121617-b22cc5ke\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "experiment = 'baseline without TTA'\n",
        "run = wandb.init(project='BiasGuardRF1', reinit = True)\n",
        "print(experiment)\n",
        "print('equal opportunity for tpr: ', np.mean(op), np.var(op))\n",
        "print('equal opportunity for fpr: ',np.mean(op_f), np.var(op_f))\n",
        "print('avarage absolute odds difference: ', np.mean(od), np.var(od))\n",
        "print('accuracy: ', np.mean(acc), np.var(acc))\n",
        "wandb.log({'dataset' : DATASET_NAME, 'model' : EXP, 'experiment' : experiment,\n",
        "            'accuracy' : np.mean(acc), 'acc_var': np.var(acc),'dTPR' : np.mean(op), 'dFPR':np.mean(op_f),\n",
        "            'avarge odd' : np.mean(od),'odd_var': np.var(od), 'DI':np.mean(d_i), 'DI_var': np.var(d_i), 'flips': None,'time' : str(time_elapsed_baseline) }, step=0)\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        },
        "id": "-Jaj7SXD7m2h",
        "outputId": "3995ae46-f929-47b6-dcf0-4f2f793b7e2f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\seffi\\OneDrive\\Public\\Documents\\PostDoc\\BiasG\\wandb\\run-20250114_121621-d76ba3go</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/d76ba3go' target=\"_blank\">leafy-monkey-54</a></strong> to <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/d76ba3go' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/d76ba3go</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "baseline with ThresholdOptimizer\n",
            "tpr0:  0.7536449920896082  tpr1:  0.7302904167232  delta:  0.02335457536640817\n",
            "fpr0:  0.13425425721896422 fpr1:  0.09605771263689108  delta:  0.03819654458207314\n",
            "equal opportunity for tpr:  0.10952441700266399\n",
            "equal opportunity for fpr:  0.07388114620612991\n",
            "avarage absolute odds difference:  0.09170278160439696\n",
            "accuracy:  0.8370000000000001\n",
            "Time:  0:00:01.274879\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DI</td><td>▁</td></tr><tr><td>DI_var</td><td>▁</td></tr><tr><td>acc_var</td><td>▁</td></tr><tr><td>accuracy</td><td>▁</td></tr><tr><td>avarge odd</td><td>▁</td></tr><tr><td>dFPR</td><td>▁</td></tr><tr><td>dTPR</td><td>▁</td></tr><tr><td>flips</td><td>▁</td></tr><tr><td>odd_var</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DI</td><td>0.89738</td></tr><tr><td>DI_var</td><td>0.01112</td></tr><tr><td>acc_var</td><td>7e-05</td></tr><tr><td>accuracy</td><td>0.837</td></tr><tr><td>avarge odd</td><td>0.0917</td></tr><tr><td>dFPR</td><td>0.07388</td></tr><tr><td>dTPR</td><td>0.10952</td></tr><tr><td>dataset</td><td>RECRUIT_SEX</td></tr><tr><td>experiment</td><td>baseline with Thresh...</td></tr><tr><td>flips</td><td>285</td></tr><tr><td>model</td><td>RF</td></tr><tr><td>odd_var</td><td>0.00146</td></tr><tr><td>time</td><td>0:00:01.274879</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">leafy-monkey-54</strong> at: <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/d76ba3go' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/d76ba3go</a><br> View project at: <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20250114_121621-d76ba3go\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "experiment = 'baseline with ThresholdOptimizer'\n",
        "run = wandb.init(project='BiasGuardRF1', reinit=True)\n",
        "print(experiment)\n",
        "print('tpr0: ', np.mean(tpr_0_tho) , ' tpr1: ', np.mean(tpr_1_tho), ' delta: ', abs(np.mean(tpr_0_tho) - np.mean(tpr_1_tho)))\n",
        "print('fpr0: ', np.mean(fpr_0_tho), 'fpr1: ', np.mean(fpr_1_tho), ' delta: ', abs(np.mean(fpr_0_tho) - np.mean(fpr_1_tho)))\n",
        "print('equal opportunity for tpr: ',np.mean(op_tho))\n",
        "print('equal opportunity for fpr: ',np.mean(op_f_tho))\n",
        "print('avarage absolute odds difference: ',np.mean(od_tho))\n",
        "print('accuracy: ', np.mean(acc_tho))\n",
        "print('Time: ',time_elapsed_tho)\n",
        "wandb.log({'dataset' : DATASET_NAME, 'model' : EXP, 'experiment' : experiment,\n",
        "            'accuracy' : np.mean(acc_tho), 'acc_var':np.var(acc_tho) ,'dTPR' : np.mean(op_tho), 'dFPR':np.mean(op_f_tho),\n",
        "            'avarge odd' : np.mean(od_tho),'odd_var': np.var(od_tho), 'DI':np.mean(d_i_tho), 'DI_var': np.var(d_i_tho), 'flips': flips, 'time' : str(time_elapsed_tho) }, step=0)\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55p9bsSMMqmp"
      },
      "source": [
        "CTGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xkKs-5YgZLOH"
      },
      "outputs": [],
      "source": [
        "from sdv.sampling import Condition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caaLiCQUMuTC",
        "outputId": "6178eff2-ba0e-407a-c46d-0d54523d74a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Sampling conditions: 100%|██████████| 4000/4000 [00:00<00:00, 8956.28it/s]\n",
            "Sampling conditions: 100%|██████████| 4000/4000 [00:00<00:00, 6206.20it/s]\n"
          ]
        }
      ],
      "source": [
        "if DATASET_NAME == 'ADULT_SEX':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_adult_sex.pkl')\n",
        "elif DATASET_NAME == 'COMPAS_SEX':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_compas_sex.pkl')\n",
        "elif DATASET_NAME == 'CREDIT_SEX':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_credit_sex.pkl')\n",
        "elif DATASET_NAME == 'RECRUIT_SEX':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_recruit_sex.pkl')\n",
        "elif DATASET_NAME == 'DIABETES_AGE':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_diabetes_age.pkl')\n",
        "elif DATASET_NAME == 'BANK_AGE':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_bank_age.pkl')\n",
        "elif DATASET_NAME == 'DEFAULT_CREDIT_SEX':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_default_credit_sex.pkl')\n",
        "elif DATASET_NAME == 'NURSERY_OCC':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_nursery_occ.pkl')\n",
        "elif DATASET_NAME == 'COMPAS_RACE':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_compas_race.pkl')\n",
        "elif DATASET_NAME == 'ADULT_RACE':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_adult_race.pkl')\n",
        "elif DATASET_NAME == 'MIMIC_SEX':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_mimic_sex.pkl')\n",
        "elif DATASET_NAME == 'MATERNAL_AGE':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_maternal_age.pkl')\n",
        "elif DATASET_NAME == 'MESO_SEX':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_meso_sex.pkl')\n",
        "elif DATASET_NAME == 'SURGICAL_SEX':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_surgical_sex.pkl')\n",
        "elif DATASET_NAME == 'SURGICAL_AGE':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_surgical_age.pkl')\n",
        "elif DATASET_NAME == 'DUTCH_SEX':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_dutch_sex.pkl')\n",
        "elif DATASET_NAME == 'LAW_SEX':\n",
        "    ctgan = CTGANSynthesizer.load('ctgan_law_sex.pkl')\n",
        "synthetic_data = ctgan.sample(data.shape[0]*CTGAN_FACTOR)\n",
        "synthetic_data.head(10)\n",
        "condition_0 = Condition({PRIV_FEATURE: 0}, num_rows=data.shape[0])\n",
        "condition_1 = Condition({PRIV_FEATURE: 1}, num_rows=data.shape[0])\n",
        "synthetic_data_0 = ctgan.sample_from_conditions(conditions=[condition_0])\n",
        "synthetic_data_1 = ctgan.sample_from_conditions(conditions=[condition_1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "t-JNmrDFBmcl"
      },
      "outputs": [],
      "source": [
        "synthetic_data =  encoder.transform(synthetic_data)\n",
        "synthetic_data_0 =  encoder.transform(synthetic_data_0)\n",
        "synthetic_data_1 =  encoder.transform(synthetic_data_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPHOJi32E96F"
      },
      "source": [
        "random forest TTA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p1RGx0UCwD1"
      },
      "source": [
        "# CTGAN TTA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "O3hAk6aPCyNq"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "svd = TruncatedSVD(n_components=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ATpY-n4lC1DJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import Normalizer\n",
        "synthetic_data = synthetic_data.dropna()\n",
        "transformer = Normalizer().fit(synthetic_data.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "5hvlKrcYC4lX",
        "outputId": "959a8f2e-3151-407c-d5b1-4420440efe09"
      },
      "outputs": [],
      "source": [
        "svd_data = svd.fit_transform(transformer.transform(data.values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "OBxnc7TiC8wL",
        "outputId": "6f73ea8f-5c40-4745-c8c5-72fc7ef0205f"
      },
      "outputs": [],
      "source": [
        "svd_synthdata = svd.transform(transformer.transform(synthetic_data.values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "35IaqG63DB7w"
      },
      "outputs": [],
      "source": [
        "nbrs = NearestNeighbors(n_neighbors=2,metric='cosine').fit(synthetic_data.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "OoK190pWDFW0",
        "outputId": "1b8c8236-1fa3-4cc4-9878-69370b629490"
      },
      "outputs": [],
      "source": [
        "synthetic_data_0 = synthetic_data_0.dropna()\n",
        "synthetic_data_1 = synthetic_data_1.dropna()\n",
        "svd_synthdata_0 = svd.transform(transformer.transform(synthetic_data_0.values))\n",
        "svd_synthdata_1 = svd.transform(transformer.transform(synthetic_data_1.values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "PQawg0T_DJz6"
      },
      "outputs": [],
      "source": [
        "nbrs_0 = NearestNeighbors(n_neighbors=1,metric='cosine',n_jobs=-1).fit(svd_synthdata_0)\n",
        "nbrs_1 = NearestNeighbors(n_neighbors=1,metric='cosine',n_jobs=-1).fit(svd_synthdata_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Sgh6g9N4DQuH"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>nationality</th>\n",
              "      <th>sport</th>\n",
              "      <th>ind-university_grade</th>\n",
              "      <th>ind-debateclub</th>\n",
              "      <th>ind-programming_exp</th>\n",
              "      <th>ind-international_exp</th>\n",
              "      <th>ind-entrepeneur_exp</th>\n",
              "      <th>ind-languages</th>\n",
              "      <th>ind-exact_study</th>\n",
              "      <th>ind-degree</th>\n",
              "      <th>company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.308756</td>\n",
              "      <td>0.353206</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.467588</td>\n",
              "      <td>0.323162</td>\n",
              "      <td>0.291976</td>\n",
              "      <td>0.461454</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.33597</td>\n",
              "      <td>0.204637</td>\n",
              "      <td>0.424</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender   age  nationality     sport  ind-university_grade  ind-debateclub  \\\n",
              "0     0.0  27.0     0.308756  0.353206                  60.0        0.467588   \n",
              "\n",
              "   ind-programming_exp  ind-international_exp  ind-entrepeneur_exp  \\\n",
              "0             0.323162               0.291976             0.461454   \n",
              "\n",
              "   ind-languages  ind-exact_study  ind-degree  company  \n",
              "0            2.0          0.33597    0.204637    0.424  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(data.iloc[test].iloc[i].values.reshape(1,-1),columns=data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "SekKc5PNm218"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calc_bias(\n",
        "    X,\n",
        "    y,\n",
        "    priv_feature_idx,\n",
        "    y_pred,\n",
        "    experiment_text\n",
        "):\n",
        "    \"\"\"Calculate bias metrics with purely NumPy-based logic.\"\"\"\n",
        "    # Ensure all inputs are NumPy arrays\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "\n",
        "    print(\"performance for whole ds:\" + experiment_text)\n",
        "    fpr, tpr, acc = print_metrics(y, y_pred)\n",
        "\n",
        "    # Unique categories in the privileged feature column\n",
        "    feature_categories = np.unique(X[:, priv_feature_idx])\n",
        "    # e.g. cat0=0, cat1=1\n",
        "    cat0, cat1 = feature_categories[0], feature_categories[1]\n",
        "\n",
        "    # Boolean masks for each subgroup\n",
        "    mask0 = (X[:, priv_feature_idx] == cat0)\n",
        "    mask1 = (X[:, priv_feature_idx] == cat1)\n",
        "\n",
        "    # Slice out each group\n",
        "    y0 = y[mask0]\n",
        "    y_pred0 = y_pred[mask0]\n",
        "    y1 = y[mask1]\n",
        "    y_pred1 = y_pred[mask1]\n",
        "\n",
        "    print(\"performance for 0 sub-group:\")\n",
        "    fpr_0, tpr_0, acc_0 = print_metrics(y0, y_pred0)\n",
        "\n",
        "    print(\"performance for 1 sub-group:\")\n",
        "    fpr_1, tpr_1, acc_1 = print_metrics(y1, y_pred1)\n",
        "\n",
        "    op_diff = opportunity_diff_tpr(tpr_0, tpr_1)\n",
        "    op_diff_fpr = opportunity_diff_fpr(fpr_0, fpr_1)\n",
        "    od_diff = odds_diff(tpr_0, tpr_1, fpr_0, fpr_1)\n",
        "\n",
        "    print(\"bias metrics:\")\n",
        "    print(\"average absolute odds difference: (close to 0)\", od_diff)\n",
        "\n",
        "    # disparate_impact must handle two 1D arrays\n",
        "    di = disparate_impact(y_pred0.astype(int), y_pred1.astype(int))\n",
        "\n",
        "    return (op_diff, op_diff_fpr, od_diff, acc, fpr_0, tpr_0, fpr_1, tpr_1, di)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "w6dMPvOluVs5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert dataframes/series to NumPy arrays\n",
        "data_array = data.to_numpy()\n",
        "y_array = y.to_numpy()\n",
        "\n",
        "synthetic_data_0_array = synthetic_data_0.to_numpy()\n",
        "synthetic_data_1_array = synthetic_data_1.to_numpy()\n",
        "svd_synthdata_0_array = svd_synthdata_0\n",
        "svd_synthdata_1_array = svd_synthdata_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "2E8f3BZQy2kx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "performance for whole ds:subexperiment - CTGAN TTA fold:0\n",
            "conf matrix:\n",
            "  [[514  32]\n",
            " [ 83 171]] \n",
            "accuracy:  0.85625 precision:  0.8423645320197044 recall:  0.6732283464566929 fpr:  0.05860805860805861 tpr:  0.6732283464566929 fn+fp 115\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[230  24]\n",
            " [ 48 103]] \n",
            "accuracy:  0.8222222222222222 precision:  0.8110236220472441 recall:  0.6821192052980133 fpr:  0.09448818897637795 tpr:  0.6821192052980133 fn+fp 72\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[284   8]\n",
            " [ 35  68]] \n",
            "accuracy:  0.8911392405063291 precision:  0.8947368421052632 recall:  0.6601941747572816 fpr:  0.0273972602739726 tpr:  0.6601941747572816 fn+fp 43\n",
            "bias metrics:\n",
            "average absolute odds difference: (close to 0) 0.04450797962156852\n",
            "performance for whole ds:subexperiment - CTGAN TTA fold:1\n",
            "conf matrix:\n",
            "  [[504  42]\n",
            " [ 76 178]] \n",
            "accuracy:  0.8525 precision:  0.8090909090909091 recall:  0.7007874015748031 fpr:  0.07692307692307693 tpr:  0.7007874015748031 fn+fp 118\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[250  28]\n",
            " [ 32 110]] \n",
            "accuracy:  0.8571428571428571 precision:  0.7971014492753623 recall:  0.7746478873239436 fpr:  0.10071942446043165 tpr:  0.7746478873239436 fn+fp 60\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[254  14]\n",
            " [ 44  68]] \n",
            "accuracy:  0.8473684210526315 precision:  0.8292682926829268 recall:  0.6071428571428571 fpr:  0.05223880597014925 tpr:  0.6071428571428571 fn+fp 58\n",
            "bias metrics:\n",
            "average absolute odds difference: (close to 0) 0.10799282433568447\n",
            "performance for whole ds:subexperiment - CTGAN TTA fold:2\n",
            "conf matrix:\n",
            "  [[504  43]\n",
            " [ 76 177]] \n",
            "accuracy:  0.85125 precision:  0.8045454545454546 recall:  0.6996047430830039 fpr:  0.07861060329067641 tpr:  0.6996047430830039 fn+fp 119\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[268  27]\n",
            " [ 40 110]] \n",
            "accuracy:  0.849438202247191 precision:  0.8029197080291971 recall:  0.7333333333333333 fpr:  0.09152542372881356 tpr:  0.7333333333333333 fn+fp 67\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[236  16]\n",
            " [ 36  67]] \n",
            "accuracy:  0.8535211267605634 precision:  0.8072289156626506 recall:  0.6504854368932039 fpr:  0.06349206349206349 tpr:  0.6504854368932039 fn+fp 52\n",
            "bias metrics:\n",
            "average absolute odds difference: (close to 0) 0.05544062833843971\n",
            "performance for whole ds:subexperiment - CTGAN TTA fold:3\n",
            "conf matrix:\n",
            "  [[513  34]\n",
            " [ 79 174]] \n",
            "accuracy:  0.85875 precision:  0.8365384615384616 recall:  0.6877470355731226 fpr:  0.062157221206581355 tpr:  0.6877470355731226 fn+fp 113\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[249  19]\n",
            " [ 44 105]] \n",
            "accuracy:  0.8489208633093526 precision:  0.8467741935483871 recall:  0.7046979865771812 fpr:  0.0708955223880597 tpr:  0.7046979865771812 fn+fp 63\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[264  15]\n",
            " [ 35  69]] \n",
            "accuracy:  0.8694516971279374 precision:  0.8214285714285714 recall:  0.6634615384615384 fpr:  0.053763440860215055 tpr:  0.6634615384615384 fn+fp 50\n",
            "bias metrics:\n",
            "average absolute odds difference: (close to 0) 0.0291842648217437\n",
            "performance for whole ds:subexperiment - CTGAN TTA fold:4\n",
            "conf matrix:\n",
            "  [[499  48]\n",
            " [ 80 173]] \n",
            "accuracy:  0.84 precision:  0.7828054298642534 recall:  0.6837944664031621 fpr:  0.08775137111517367 tpr:  0.6837944664031621 fn+fp 128\n",
            "performance for 0 sub-group:\n",
            "conf matrix:\n",
            "  [[255  27]\n",
            " [ 44 114]] \n",
            "accuracy:  0.8386363636363636 precision:  0.8085106382978723 recall:  0.7215189873417721 fpr:  0.09574468085106383 tpr:  0.7215189873417721 fn+fp 71\n",
            "performance for 1 sub-group:\n",
            "conf matrix:\n",
            "  [[244  21]\n",
            " [ 36  59]] \n",
            "accuracy:  0.8416666666666667 precision:  0.7375 recall:  0.6210526315789474 fpr:  0.07924528301886792 tpr:  0.6210526315789474 fn+fp 57\n",
            "bias metrics:\n",
            "average absolute odds difference: (close to 0) 0.058482876797510304\n",
            "Time elapsed for CTGAN TTA: 0:00:06.306459\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from datetime import datetime\n",
        "\n",
        "fprs, tprs, scores = [], [], []\n",
        "op_tta4, op_f_tta4, od_tta4, acc_tta4, d_i_tta4 = [], [], [], [], []\n",
        "swaps_count = 0\n",
        "start_time = datetime.now()\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(cv.split(data_array, y_array)):\n",
        "    # Fit on the training slice\n",
        "    clf.fit(data_array[train_idx, :], y_array[train_idx])\n",
        "\n",
        "    y_pred_tta = []\n",
        "    for i in range(len(test_idx)):\n",
        "\n",
        "        # Get the original row (shape = (n_features,))\n",
        "        row = data_array[test_idx[i], :]\n",
        "\n",
        "        # Expand to 2D for predict_proba (shape = (1, n_features))\n",
        "        tta_ds = np.expand_dims(row, axis=0)\n",
        "\n",
        "        # Quick check on predicted probability\n",
        "        prob_tta_ds = np.mean(clf.predict_proba(tta_ds)[:, 1])\n",
        "        y_pred_temp = round(prob_tta_ds)\n",
        "\n",
        "        # Create “opposite” sample\n",
        "        sample_opposite = row.copy()\n",
        "        sample_opposite[PROT_ATTR_IDX] = abs(1 - sample_opposite[PROT_ATTR_IDX])\n",
        "\n",
        "        prob_opposite = np.mean(\n",
        "            clf.predict_proba(sample_opposite.reshape(1, -1))[:, 1]\n",
        "        )\n",
        "\n",
        "        # If the difference in predicted outcomes is 1 when rounded\n",
        "        if abs(round(prob_tta_ds) - round(prob_opposite)) == 1:\n",
        "            # If the privileged feature is 1\n",
        "            if row[PROT_ATTR_IDX] == 1:\n",
        "                # Use nearest neighbors from \"0\" group\n",
        "                ind = nbrs_0.kneighbors(\n",
        "                    svd_synthdata_0_array[i].reshape(1, -1),\n",
        "                    n_neighbors=N_AUG,\n",
        "                    return_distance=False\n",
        "                )\n",
        "                for j in range(N_AUG):\n",
        "                    new_row = synthetic_data_0_array[ind[0][j], :]  # shape = (n_features,)\n",
        "                    # Concatenate a (1, n_features) array\n",
        "                    tta_ds = np.concatenate((tta_ds, new_row[np.newaxis, :]), axis=0)\n",
        "            else:\n",
        "                # Use nearest neighbors from \"1\" group\n",
        "                ind = nbrs_1.kneighbors(\n",
        "                    svd_synthdata_1_array[i].reshape(1, -1),\n",
        "                    n_neighbors=N_AUG,\n",
        "                    return_distance=False\n",
        "                )\n",
        "                for j in range(N_AUG):\n",
        "                    new_row = synthetic_data_1_array[ind[0][j], :]\n",
        "                    tta_ds = np.concatenate((tta_ds, new_row[np.newaxis, :]), axis=0)\n",
        "\n",
        "            # Add duplicates of the original row (N_AUG - 1) times\n",
        "            for _ in range(N_AUG - 1):\n",
        "                tta_ds = np.concatenate((tta_ds, row[np.newaxis, :]), axis=0)\n",
        "\n",
        "        # Final TTA prediction\n",
        "        tta_prob_mean = np.mean(clf.predict_proba(tta_ds)[:, 1])\n",
        "        y_pred_tta.append(round(tta_prob_mean))\n",
        "\n",
        "    o_p, o_p_fpr, o_d, acc, fpr_0, tpr_0, fpr_1, tpr_1, d_i = calc_bias(\n",
        "        data_array[test_idx, :],\n",
        "        y_array[test_idx],\n",
        "        PROT_ATTR_IDX,\n",
        "        y_pred_tta,\n",
        "        f\"subexperiment - CTGAN TTA fold:{fold}\"\n",
        "    )\n",
        "    op_tta4.append(o_p)\n",
        "    op_f_tta4.append(o_p_fpr)\n",
        "    od_tta4.append(o_d)\n",
        "    acc_tta4.append(acc)\n",
        "    d_i_tta4.append(d_i)\n",
        "\n",
        "time_elapsed_ctgan = datetime.now() - start_time\n",
        "print(\"Time elapsed for CTGAN TTA:\", time_elapsed_ctgan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5kGrYiu3K3hL"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\seffi\\OneDrive\\Public\\Documents\\PostDoc\\BiasG\\wandb\\run-20250114_121633-bip1cwfj</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/bip1cwfj' target=\"_blank\">cool-sound-55</a></strong> to <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/bip1cwfj' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/bip1cwfj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BiasGuard TTA6\n",
            "equal opportunity for tpr:  0.08279615220808301\n",
            "equal opportunity for fpr:  0.03544727735789568\n",
            "avarage absolute odds difference:  0.059121714782989346\n",
            "accuracy:  0.85175\n",
            "time:  0:00:06.306459\n",
            "swaps count:  0\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DI</td><td>▁</td></tr><tr><td>DI_var</td><td>▁</td></tr><tr><td>acc_var</td><td>▁</td></tr><tr><td>accuracy</td><td>▁</td></tr><tr><td>avarge odd</td><td>▁</td></tr><tr><td>dFPR</td><td>▁</td></tr><tr><td>dTPR</td><td>▁</td></tr><tr><td>flips</td><td>▁</td></tr><tr><td>odd_var</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DI</td><td>0.69215</td></tr><tr><td>DI_var</td><td>0.0028</td></tr><tr><td>acc_var</td><td>4e-05</td></tr><tr><td>accuracy</td><td>0.85175</td></tr><tr><td>avarge odd</td><td>0.05912</td></tr><tr><td>dFPR</td><td>0.03545</td></tr><tr><td>dTPR</td><td>0.0828</td></tr><tr><td>dataset</td><td>RECRUIT_SEX</td></tr><tr><td>experiment</td><td>BiasGuard TTA6</td></tr><tr><td>flips</td><td>0</td></tr><tr><td>model</td><td>RF</td></tr><tr><td>odd_var</td><td>0.0007</td></tr><tr><td>time</td><td>0:00:06.306459</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cool-sound-55</strong> at: <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/bip1cwfj' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1/runs/bip1cwfj</a><br> View project at: <a href='https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1' target=\"_blank\">https://wandb.ai/rabaevn-ben-gurion-university-of-the-negev/BiasGuardRF1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20250114_121633-bip1cwfj\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "experiment = 'BiasGuard TTA'+str(N_AUG)\n",
        "run = wandb.init(project='BiasGuardRF1', reinit=True)\n",
        "print(experiment)\n",
        "print('equal opportunity for tpr: ',np.mean(op_tta4))\n",
        "print('equal opportunity for fpr: ',np.mean(op_f_tta4))\n",
        "print('avarage absolute odds difference: ',np.mean(od_tta4))\n",
        "print('accuracy: ', np.mean(acc_tta4))\n",
        "print('time: ', time_elapsed_ctgan)\n",
        "print('swaps count: ', swaps_count)\n",
        "wandb.log({'dataset' : DATASET_NAME, 'model' : EXP, 'experiment' : experiment,\n",
        "            'accuracy' : np.mean(acc_tta4),'acc_var': np.var(acc_tta4), 'dTPR' : np.mean(op_tta4), 'dFPR':np.mean(op_f_tta4),\n",
        "            'avarge odd' : np.mean(od_tta4),'odd_var': np.var(od_tta4), 'DI':np.mean(d_i_tta4), 'DI_var': np.var(d_i_tta4), 'flips': swaps_count, 'time' : str(time_elapsed_ctgan) }, step=0)\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 225,
          "sourceId": 498,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 1498,
          "sourceId": 2680,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4471,
          "sourceId": 6849,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 9109,
          "sourceId": 12699,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 2126839,
          "sourceId": 3536315,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 2438820,
          "sourceId": 4127094,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 2503608,
          "sourceId": 4287421,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 2654648,
          "sourceId": 4545860,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 2736221,
          "sourceId": 4728572,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 3205395,
          "sourceId": 5567643,
          "sourceType": "datasetVersion"
        },
        {
          "sourceId": 128183621,
          "sourceType": "kernelVersion"
        }
      ],
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "kats",
      "language": "python",
      "name": "kats"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
